{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef7b86b-70dc-4dc1-bcb9-492e2f8fe694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "import torch\n",
    "from transformers import LlamaTokenizer, LlamaModel, AutoModelForCausalLM, LlamaForCausalLM, GenerationConfig, LlamaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "489de039-4a87-446e-b114-59faaad93bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Tokenizer loaded.\n",
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6117b1309204309aedbd56b29b87c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m model: LlamaForCausalLM \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    566\u001b[0m     )\n\u001b[1;32m    567\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:3916\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3906\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3907\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3909\u001b[0m     (\n\u001b[1;32m   3910\u001b[0m         model,\n\u001b[1;32m   3911\u001b[0m         missing_keys,\n\u001b[1;32m   3912\u001b[0m         unexpected_keys,\n\u001b[1;32m   3913\u001b[0m         mismatched_keys,\n\u001b[1;32m   3914\u001b[0m         offload_index,\n\u001b[1;32m   3915\u001b[0m         error_msgs,\n\u001b[0;32m-> 3916\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[1;32m   3917\u001b[0m         model,\n\u001b[1;32m   3918\u001b[0m         state_dict,\n\u001b[1;32m   3919\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3920\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3921\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3922\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[1;32m   3923\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[1;32m   3924\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[1;32m   3925\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[1;32m   3926\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   3927\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   3928\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m   3929\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m   3930\u001b[0m         hf_quantizer\u001b[39m=\u001b[39;49mhf_quantizer,\n\u001b[1;32m   3931\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[1;32m   3932\u001b[0m         gguf_path\u001b[39m=\u001b[39;49mgguf_path,\n\u001b[1;32m   3933\u001b[0m     )\n\u001b[1;32m   3935\u001b[0m \u001b[39m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3936\u001b[0m model\u001b[39m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:4414\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4410\u001b[0m     \u001b[39mif\u001b[39;00m assign_to_params_buffers \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4411\u001b[0m         assign_to_params_buffers \u001b[39m=\u001b[39m check_support_param_buffer_assignment(\n\u001b[1;32m   4412\u001b[0m             model_to_load, state_dict, start_prefix\n\u001b[1;32m   4413\u001b[0m         )\n\u001b[0;32m-> 4414\u001b[0m     error_msgs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m _load_state_dict_into_model(\n\u001b[1;32m   4415\u001b[0m         model_to_load, state_dict, start_prefix, assign_to_params_buffers\n\u001b[1;32m   4416\u001b[0m     )\n\u001b[1;32m   4418\u001b[0m \u001b[39m# force memory release\u001b[39;00m\n\u001b[1;32m   4419\u001b[0m \u001b[39mdel\u001b[39;00m state_dict\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:748\u001b[0m, in \u001b[0;36m_load_state_dict_into_model\u001b[0;34m(model_to_load, state_dict, start_prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[39mif\u001b[39;00m child \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m             load(child, state_dict, prefix \u001b[39m+\u001b[39m name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, assign_to_params_buffers)\n\u001b[0;32m--> 748\u001b[0m load(model_to_load, state_dict, prefix\u001b[39m=\u001b[39;49mstart_prefix, assign_to_params_buffers\u001b[39m=\u001b[39;49massign_to_params_buffers)\n\u001b[1;32m    749\u001b[0m \u001b[39m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[39m# it's safe to delete it.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \u001b[39mdel\u001b[39;00m state_dict\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:746\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    745\u001b[0m     \u001b[39mif\u001b[39;00m child \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m         load(child, state_dict, prefix \u001b[39m+\u001b[39;49m name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m, assign_to_params_buffers)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:746\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    745\u001b[0m     \u001b[39mif\u001b[39;00m child \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m         load(child, state_dict, prefix \u001b[39m+\u001b[39;49m name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m, assign_to_params_buffers)\n",
      "    \u001b[0;31m[... skipping similar frames: _load_state_dict_into_model.<locals>.load at line 746 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:746\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    745\u001b[0m     \u001b[39mif\u001b[39;00m child \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m         load(child, state_dict, prefix \u001b[39m+\u001b[39;49m name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m, assign_to_params_buffers)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:742\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[0;34m(module, state_dict, prefix, assign_to_params_buffers)\u001b[0m\n\u001b[1;32m    740\u001b[0m                     module\u001b[39m.\u001b[39m_load_from_state_dict(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    741\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 742\u001b[0m         module\u001b[39m.\u001b[39;49m_load_from_state_dict(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    744\u001b[0m \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    745\u001b[0m     \u001b[39mif\u001b[39;00m child \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:2075\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m             \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m, name, input_param)\n\u001b[1;32m   2074\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2075\u001b[0m             param\u001b[39m.\u001b[39;49mcopy_(input_param)\n\u001b[1;32m   2076\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m   2077\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mswapping\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m use_swap_tensors \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcopying\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 全局加载LLaMA-2-7B模型\n",
    "model_name_or_path = \"/mnt/bn/data-tns-live-llm/leon/datasets/Llama-2-7b-hf\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer: LlamaTokenizer = LlamaTokenizer.from_pretrained(model_name_or_path, local_files_only=True, model_max_length=512)\n",
    "# 设置pad_token为eos_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(\"Tokenizer loaded.\")\n",
    "\n",
    "print(\"Loading model...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model: LlamaForCausalLM = AutoModelForCausalLM.from_pretrained(model_name_or_path, local_files_only=True)\n",
    "model.to(device)\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32c6d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer(\"introduce the film Marriage story\", return_tensors=\"pt\")\n",
    "output = model.generate(input[\"input_ids\"].cuda(), max_length=512).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ed51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.decode(output[0])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20abf795-81bc-45f8-bd1c-b761940d255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_pickle(file_path)\n",
    "\n",
    "def load_movie_dict(item_file):\n",
    "    item_df = pd.read_csv(item_file, sep='|', header=None, encoding='latin-1', usecols=[0, 1])\n",
    "    item_df.columns = ['movie_id', 'movie_title']\n",
    "    movie_dict = dict(zip(item_df['movie_id'], item_df['movie_title']))\n",
    "    return movie_dict\n",
    "\n",
    "def map_movie_names_only(seq, movie_dict):\n",
    "    return [movie_dict[id] if id in movie_dict else id for (id, rating) in seq]\n",
    "\n",
    "def extract_sequences(df, movie_dict):\n",
    "    df['movie_names_only'] = df['seq'].apply(lambda x: map_movie_names_only(x, movie_dict))\n",
    "    df['seq_only'] = df['seq'].apply(lambda x: [id for (id, rating) in x])\n",
    "    return df\n",
    "\n",
    "def get_movie_embeddings(movie_list):\n",
    "    embeddings = []\n",
    "    max_length = 512  # 设定一个合理的最大长度\n",
    "    for movies in movie_list:\n",
    "        movie_string = \" \".join(str(movie) for movie in movies)\n",
    "        inputs = tokenizer(movie_string, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            movie_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "        embeddings.append(movie_embedding)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "def calculate_dtw_distance(embedding_seq1, embedding_seq2):\n",
    "    # 将向量调整为二维数组，以便 fastdtw 正确处理\n",
    "    embedding_seq1 = embedding_seq1.reshape(-1, 1)\n",
    "    embedding_seq2 = embedding_seq2.reshape(-1, 1)\n",
    "    distance, path = fastdtw(embedding_seq1, embedding_seq2, dist=euclidean)\n",
    "    return distance\n",
    "\n",
    "def calculate_similarity(df):\n",
    "    movie_embeddings = get_movie_embeddings(df['movie_names_only'].tolist())\n",
    "    df['movie_embeddings'] = list(movie_embeddings)\n",
    "    embeddings = np.stack(df['movie_embeddings'].values)\n",
    "    \n",
    "    most_similar_indices = []\n",
    "    for i, embedding_seq1 in enumerate(embeddings):\n",
    "        min_distance = float('inf')\n",
    "        most_similar_index = -1\n",
    "        for j, embedding_seq2 in enumerate(embeddings):\n",
    "            if i != j:\n",
    "                distance = calculate_dtw_distance(embedding_seq1, embedding_seq2)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    most_similar_index = j\n",
    "        most_similar_indices.append(most_similar_index)\n",
    "    \n",
    "    df['most_similar_seq_index'] = most_similar_indices\n",
    "    df['most_similar_seq'] = df['most_similar_seq_index'].apply(lambda idx: df.at[idx, 'seq'])\n",
    "    return df\n",
    "\n",
    "def add_most_similar_seq_next(df, movie_dict):\n",
    "    df['most_similar_seq_next'] = df['next'].iloc[df['most_similar_seq_index']].values\n",
    "    df['most_similar_seq_name'] = df['most_similar_seq'].apply(lambda x: [movie_dict.get(item[0], \"Unknown\") for item in x])\n",
    "    df['most_similar_seq_next_name'] = df['most_similar_seq_next'].apply(lambda x: movie_dict.get(x[0], \"Unknown\"))\n",
    "    return df\n",
    "\n",
    "def save_data(df, output_file_path):\n",
    "    df.to_pickle(output_file_path)\n",
    "\n",
    "def process_data(file_path, item_file, output_file_path):\n",
    "    df = load_data(file_path)\n",
    "    movie_dict = load_movie_dict(item_file)\n",
    "    df = extract_sequences(df, movie_dict)\n",
    "    df = calculate_similarity(df)\n",
    "    df = add_most_similar_seq_next(df, movie_dict)\n",
    "    save_data(df, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288a939d-907b-4ead-81a3-7d57b9a54b1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m item_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/workspace/LLaRA/data/ref/movielens/u.item\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/workspace/LLaRA/data/ref/movielens/similar_val_data.df\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 69\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(file_path, item_file, output_file_path)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_data\u001b[39m(file_path, item_file, output_file_path):\n\u001b[0;32m---> 69\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     movie_dict \u001b[38;5;241m=\u001b[39m load_movie_dict(item_file)\n\u001b[1;32m     71\u001b[0m     df \u001b[38;5;241m=\u001b[39m extract_sequences(df, movie_dict)\n",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(file_path):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_pickle(file_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# 使用函数处理数据\n",
    "file_path = '/workspace/LLaRA/data/ref/movielens/train_data.df'\n",
    "item_file = '/workspace/LLaRA/data/ref/movielens/u.item'\n",
    "output_file_path = '/workspace/LLaRA/data/ref/movielens/similar_val_data.df'\n",
    "\n",
    "process_data(file_path, item_file, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f35e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
